{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "coastal-sentence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch \n",
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "infectious-telephone",
   "metadata": {},
   "outputs": [],
   "source": [
    "es=Elasticsearch([{'host':'127.0.0.1','port':9200}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aquatic-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_by_screen_name(index, name, es):\n",
    "    res= es.search(index=index,body=\n",
    "    {\n",
    "      \"query\": {\n",
    "        \"match\": {\n",
    "          \"screen_name\": name\n",
    "        }\n",
    "      }\n",
    "    })\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "frequent-block",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = search_by_screen_name(\"users\", \"BarackObama\", es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "handy-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_list(l):\n",
    "    return  [item for sublist in l for item in sublist]\n",
    "\n",
    "def common_tokens(tokens, n=20):\n",
    "    sentences = (list(itertools.chain(tokens)))\n",
    "    flat_sentences = flat_list(sentences)\n",
    "    counts = Counter(flat_sentences)\n",
    "    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "swiss-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tokens=[]\n",
    "stop_words=nltk.corpus.stopwords.words('english')\n",
    "punctuation = string.punctuation\n",
    "\n",
    "for text in (res[\"hits\"][\"hits\"][0][\"_source\"][\"full_text\"]):\n",
    "    tokens_clean = []\n",
    "    for word in word_tokenize(text):\n",
    "        if word.lower() not in stop_words and word.lower() not in punctuation and not word.isnumeric() and len(word)> 1:\n",
    "            tokens_clean.append(word.lower())\n",
    "    list_tokens.append(tokens_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "above-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = common_tokens(list_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sonic-former",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https', 5),\n",
       " ('day', 4),\n",
       " ('one', 3),\n",
       " ('aaron', 2),\n",
       " ('ever', 2),\n",
       " ('people', 2),\n",
       " ('met', 2),\n",
       " ('climate', 2),\n",
       " ('today', 2),\n",
       " ('like', 2),\n",
       " (\"'re\", 2),\n",
       " ('brave', 2),\n",
       " ('enough', 2),\n",
       " ('hank', 1),\n",
       " ('best', 1),\n",
       " ('baseball', 1),\n",
       " ('players', 1),\n",
       " ('seen', 1),\n",
       " ('strongest', 1),\n",
       " ('michelle', 1),\n",
       " ('send', 1),\n",
       " ('thoughts', 1),\n",
       " ('prayers', 1),\n",
       " ('family', 1),\n",
       " ('everyone', 1),\n",
       " ('inspired', 1),\n",
       " ('unassuming', 1),\n",
       " ('man', 1),\n",
       " ('towering', 1),\n",
       " ('example', 1)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "personal-career",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 15),\n",
       " ('and', 10),\n",
       " ('the', 9),\n",
       " (':', 6),\n",
       " (',', 6),\n",
       " ('you', 6),\n",
       " ('https', 5),\n",
       " ('a', 5),\n",
       " ('was', 4),\n",
       " ('we', 4),\n",
       " ('is', 4),\n",
       " ('for', 4),\n",
       " ('day', 4),\n",
       " ('only', 4),\n",
       " ('because', 4),\n",
       " ('one', 3),\n",
       " ('of', 3),\n",
       " ('our', 3),\n",
       " ('to', 3),\n",
       " ('this', 3),\n",
       " ('that', 3),\n",
       " ('it', 3),\n",
       " ('aaron', 2),\n",
       " ('â€™', 2),\n",
       " ('ve', 2),\n",
       " ('ever', 2),\n",
       " ('people', 2),\n",
       " ('i', 2),\n",
       " ('met', 2),\n",
       " ('by', 2)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-dodge",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
